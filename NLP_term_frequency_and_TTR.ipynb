{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_term_frequency_and_TTR.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RahulTechTutorials/NLP/blob/master/NLP_term_frequency_and_TTR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nt-UwbQ-KJlU",
        "colab_type": "text"
      },
      "source": [
        "# Term Frequency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VMdoRQOKOat",
        "colab_type": "text"
      },
      "source": [
        "Term Frequency is nothing but the count of the number of words in your text. We use FreqDist class to calculate the frequency distribution in any given text.\n",
        "\n",
        "The class FreqDist  works like a dictionary where the keys are the words in the text and the values are the count associated with that word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuAOuO0cOw6N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from nltk.probability import FreqDist\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlck2XJiPGi8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ebda3870-d6d7-4595-a118-db9582d96c04"
      },
      "source": [
        "#nltk.download('stopwords')\n",
        "stopwords = set(stopwords.words('english'))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJZVAVv8Phuz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#nltk.download('gutenberg')\n",
        "words = nltk.Text(nltk.corpus.gutenberg.words('bryant-stories.txt'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnNoYpIiPwsb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Converting to small case\n",
        "words = [word.lower() for word in words if word.isalpha()]\n",
        "words = [word for word in words if word not in stopwords]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89Av_YILQctf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fDist = FreqDist(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNUTqGVqQeks",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "3825a663-7b9d-4219-fff0-61edad49d90d"
      },
      "source": [
        "for x,v in fDist.most_common(10):\n",
        "  print(x,':',v)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "little : 597\n",
            "said : 453\n",
            "came : 191\n",
            "one : 183\n",
            "could : 158\n",
            "king : 141\n",
            "went : 122\n",
            "would : 112\n",
            "great : 110\n",
            "day : 107\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZRcKhy1RDgf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "e764bf8c-54d6-4345-818c-8612aea11725"
      },
      "source": [
        "import numpy as np\n",
        "for x,v in fDist.most_common(10):\n",
        "  print(x,':',np.round(v/len(fDist),decimals=4))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "little : 0.1619\n",
            "said : 0.1228\n",
            "came : 0.0518\n",
            "one : 0.0496\n",
            "could : 0.0428\n",
            "king : 0.0382\n",
            "went : 0.0331\n",
            "would : 0.0304\n",
            "great : 0.0298\n",
            "day : 0.029\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g18Gs6X-GNMt",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJS4Q6c6F3eJ",
        "colab_type": "text"
      },
      "source": [
        "# Finding out the TTR - Type Token Ratio "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztBBqWq-JF8h",
        "colab_type": "text"
      },
      "source": [
        "The type-token ratio (TTR) is a measure of vocabulary variation within a written text or a\n",
        "personâ€™s speech. The type-token ratios of two real world examples are calculated and interpreted.\n",
        "The type-token ratio is shown to be a helpful measure of lexical variety within a text. It can be used\n",
        "to monitor changes in children and adults with vocabulary difficulties.\n",
        "\n",
        "If we count the number of words we spoke, say 87. The number of words in a text is often referred\n",
        "to as the number of tokens. However, several of these tokens are repeated. For example, the token\n",
        "again occurs two times, the token are occurs three times, and the token and occurs five times. \n",
        "\n",
        "Say out of the total of 87 tokens in some text there are 62 so-called types (distinct words). The relationship\n",
        "between the number of types and the number of tokens is known as the type-token ratio (TTR). In this case the TTR will be (62/87)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sl_uQS3ARb0x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9es-87uGK93",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c0428493-9045-4c03-afe5-b5c7e33b0e3d"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "stopwords = set(stopwords.words('english'))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NagPBwcUGWdD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "44bd0e42-7312-42d9-e75b-31b6ecc07f5e"
      },
      "source": [
        "nltk.download('gutenberg')\n",
        "words_bryant = nltk.Text(nltk.corpus.gutenberg.words('bryant-stories.txt'))\n",
        "words_emma = nltk.Text(nltk.corpus.gutenberg.words('austen-emma.txt'))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV0UmahWGvsm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words_bryant = [word.lower() for word in words_bryant if word.isalpha()]\n",
        "words_emma = [word.lower() for word in words_emma if word.isalpha()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzyIgdIfHDxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words_bryant = [word.lower() for word in words_bryant if word not in stopwords][:15000]\n",
        "words_emma = [word.lower() for word in words_emma if word not in stopwords] [:15000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Zi89CMcHKGr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "TTR_bryant = np.round(len(set(words_bryant))/len(words_bryant),decimals=4)\n",
        "TTR_emma = np.round(len(set(words_emma))/len(words_emma), decimals= 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fs_CAu_qHfk0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "9b741624-b8f2-4413-86b7-6d80504a1f44"
      },
      "source": [
        "print('TTR_bryant = {}\\nTotal_words = {}\\nVocablory_Count = {}'.format(TTR_bryant,len(words_bryant),len(set(words_bryant))), end= '\\n\\n')\n",
        "\n",
        "print('TTR_emma = {}\\nTotal_words = {}\\nVocablory_Count = {}'.format(TTR_emma,len(words_emma),len(set(words_emma))))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TTR_bryant = 0.1864\n",
            "Total_words = 15000\n",
            "Vocablory_Count = 2796\n",
            "\n",
            "TTR_emma = 0.2183\n",
            "Total_words = 15000\n",
            "Vocablory_Count = 3274\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}